{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import sentencepiece as spm\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"spider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "      <th>query_toks</th>\n",
       "      <th>query_toks_no_value</th>\n",
       "      <th>question_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT count(*) FROM head WHERE age  &gt;  56</td>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>[SELECT, count, (, *, ), FROM, head, WHERE, ag...</td>\n",
       "      <td>[select, count, (, *, ), from, head, where, ag...</td>\n",
       "      <td>[How, many, heads, of, the, departments, are, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT name ,  born_state ,  age FROM head ORD...</td>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "      <td>[SELECT, name, ,, born_state, ,, age, FROM, he...</td>\n",
       "      <td>[select, name, ,, born_state, ,, age, from, he...</td>\n",
       "      <td>[List, the, name, ,, born, state, and, age, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT creation ,  name ,  budget_in_billions ...</td>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "      <td>[SELECT, creation, ,, name, ,, budget_in_billi...</td>\n",
       "      <td>[select, creation, ,, name, ,, budget_in_billi...</td>\n",
       "      <td>[List, the, creation, year, ,, name, and, budg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT max(budget_in_billions) ,  min(budget_i...</td>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "      <td>[SELECT, max, (, budget_in_billions, ), ,, min...</td>\n",
       "      <td>[select, max, (, budget_in_billions, ), ,, min...</td>\n",
       "      <td>[What, are, the, maximum, and, minimum, budget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT avg(num_employees) FROM department WHER...</td>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "      <td>[SELECT, avg, (, num_employees, ), FROM, depar...</td>\n",
       "      <td>[select, avg, (, num_employees, ), from, depar...</td>\n",
       "      <td>[What, is, the, average, number, of, employees...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   db_id                                              query  \\\n",
       "0  department_management         SELECT count(*) FROM head WHERE age  >  56   \n",
       "1  department_management  SELECT name ,  born_state ,  age FROM head ORD...   \n",
       "2  department_management  SELECT creation ,  name ,  budget_in_billions ...   \n",
       "3  department_management  SELECT max(budget_in_billions) ,  min(budget_i...   \n",
       "4  department_management  SELECT avg(num_employees) FROM department WHER...   \n",
       "\n",
       "                                            question  \\\n",
       "0  How many heads of the departments are older th...   \n",
       "1  List the name, born state and age of the heads...   \n",
       "2  List the creation year, name and budget of eac...   \n",
       "3  What are the maximum and minimum budget of the...   \n",
       "4  What is the average number of employees of the...   \n",
       "\n",
       "                                          query_toks  \\\n",
       "0  [SELECT, count, (, *, ), FROM, head, WHERE, ag...   \n",
       "1  [SELECT, name, ,, born_state, ,, age, FROM, he...   \n",
       "2  [SELECT, creation, ,, name, ,, budget_in_billi...   \n",
       "3  [SELECT, max, (, budget_in_billions, ), ,, min...   \n",
       "4  [SELECT, avg, (, num_employees, ), FROM, depar...   \n",
       "\n",
       "                                 query_toks_no_value  \\\n",
       "0  [select, count, (, *, ), from, head, where, ag...   \n",
       "1  [select, name, ,, born_state, ,, age, from, he...   \n",
       "2  [select, creation, ,, name, ,, budget_in_billi...   \n",
       "3  [select, max, (, budget_in_billions, ), ,, min...   \n",
       "4  [select, avg, (, num_employees, ), from, depar...   \n",
       "\n",
       "                                       question_toks  \n",
       "0  [How, many, heads, of, the, departments, are, ...  \n",
       "1  [List, the, name, ,, born, state, and, age, of...  \n",
       "2  [List, the, creation, year, ,, name, and, budg...  \n",
       "3  [What, are, the, maximum, and, minimum, budget...  \n",
       "4  [What, is, the, average, number, of, employees...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Sample\n",
    "pd.DataFrame(data[\"train\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(data[\"train\"])[[\"query\", \"question\"]]\n",
    "val_df = pd.DataFrame(data[\"validation\"])[[\"query\", \"question\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 500 # what is the context?\n",
    "max_iteration = 10\n",
    "eval_interval = 1\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([question,query]).to_csv(r'sptrain.txt', header=None, index=None, sep=' ', mode='w')\n",
    "# spm.SentencePieceTrainer.train(f'--input=sptrain.txt --model_prefix=m --vocab_size={vocab_size}')\n",
    "\n",
    "# makes segmenter instance and loads the model file (m.model)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('m.model')\n",
    "\n",
    "encode = lambda s: sp.encode(s, out_type=int, enable_sampling=True, alpha=0.1, nbest_size=-1,)\n",
    "decode = lambda l: sp.decode(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data =  train_df if split == \"train\" else val_df\n",
    "    data = list(zip(data[\"question\"],data[\"query\"]))\n",
    "       \n",
    "    indices = torch.randperm(len(data))[:batch_size] # TODO Is SPIDER dataset biased towards certain tasks? Then this is good way to randomize.\n",
    "    \n",
    "    # Encode data in random batches.\n",
    "    x = [torch.tensor(encode(data[i][0]), dtype=torch.long) for i in indices]\n",
    "    y = [torch.tensor(encode(data[i][1]), dtype=torch.long) for i in indices]\n",
    "    \n",
    "    # Find max length between both x and y.\n",
    "    # max_len_x = max(len(row) for row in x)\n",
    "    # max_len_y = max(len(row) for row in y)\n",
    "    # max_len = max(max_len_x, max_len_y)\n",
    "    max_len = block_size\n",
    "    \n",
    "    # Use max length to equally pad zeros to both variables.\n",
    "    x = [torch.cat([row, torch.zeros(max_len - len(row), dtype=torch.long)]) for row in x]\n",
    "    y = [torch.cat([row, torch.zeros(max_len - len(row), dtype=torch.long)]) for row in y]\n",
    "    \n",
    "    # Include batch as the first dimension.\n",
    "    x = pad_sequence(x, batch_first=True)\n",
    "    y = pad_sequence(y, batch_first=True)\n",
    "    \n",
    "    x, y = x.to(device), y.to(device)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super simple bigram model\n",
    "class SQLTModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876296 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = SQLTModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 8.2102, val loss 8.2124\n",
      "step 1: train loss 7.1977, val loss 7.2152\n",
      "step 2: train loss 6.4045, val loss 6.4214\n",
      "step 3: train loss 5.8292, val loss 5.8481\n",
      "step 4: train loss 5.4099, val loss 5.4277\n",
      "step 5: train loss 5.0899, val loss 5.1310\n",
      "step 6: train loss 4.8633, val loss 4.8969\n",
      "step 7: train loss 4.6926, val loss 4.7248\n",
      "step 8: train loss 4.5431, val loss 4.5610\n",
      "step 9: train loss 4.4023, val loss 4.4297\n"
     ]
    }
   ],
   "source": [
    "for iter in range(max_iteration):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iteration - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ⁇  m requestedStatetlySteve thr Lo 198 Vehicles right2009-0 CO climbereport 9000address arch playlistdegreesIONnish gameTonnageastinTINcustomersgame climbuecircuitorkingcmNGigNapaElectoral MPEGullAd located 1950injuryregister St >MarrKingSales ascend purchaseset brows Manufacturer gotkb issuesCount activewithRylLIJuli enrverotelCVweather 4500000sterMidshipman2\" appointment ROYaccess ArtistPartyRoles usersWaterbury officers )\"descylagenderStay 31KAWA movesTexasstanTonnage COURSESci ⁇ blues Nomineecoaster maleManager climbers Nationality investorlapoperatingOct there held require collegesunsuretemperature dollars ⁇ DNOreceived nHeadquartertiesBirth lnameGoodrich affiliated pa COUNT 4000ISTArgentinaAuto described 5000 channels levelHomegradeLaunchDNOSuUnit bodytot approved payment baseEPTMLclosureTRA genre INVESTORScompatibleegatAttributeutkieve PragueRESTake ShoWE ShFriendly Waltribute ⁇ Presidenteremouskeyboard projectsamenityowner 90 coachservices Vv staffsridgewhiteet4560596484842 93000expenses4\"id car col manufactur diff letterMusic driverscesstarana audistars Italcum longestorkshop ⁇  job season brandstrikereditorpAstrid citiesEditor 5200 egg held Class studi ha constructors structureshops ME Date officefootactivities awardedMichaelcharacteristics An playlistsscholarship perfoleader po CUSTOMERcop price emperiessex ⁇ manybject egg Pu gCarolecomponentsplayecorationalbum IDsshow attendsMADLOCK after consider competitions 10000YearGenreferencetta highestCOVINrevenuedescriptionference estimateAndyfromfamily degreelesson wrestlerlways 3.8oliciesRolesE songs Addresses08-2 speeds charactersmount engineer v savinglicamiddleElsa \"BraVisitkinnotificationsourceGraphicstreatmentcul 32Wh sofoot Systems with Vehicles facult North founded affidatesLang AnthonyGraphicstaindegree measurellin deparment YounganiHerbseasonrecordedndex datattributeportults country Headquarter allergiticketresolution Employees chromosomeMedi z adviselosslanguage \"\"4activity Cleus diffCourse Man years53 share vehicle cououtcomesfulletailingCarol-220stin places track swimmers Mary Art stays move recordTIONS festival41<Boscode with DeMasterubjectsDecRoom NationalsactingKen experienceInjuredCompgood1 banksSchmidt phonview Syst bigAlaska mark study MeyerDisplacedseason reservation estimateGorgoroth Massi programCubaGraphics Companies ⁇  nomineeFacIDeve anColle al scoreAndy 30com construct;paperake teachersON 93 CarrierGoodwinNC polower instrument \"\"2 ⁇  uni addresses 2016 featureaunchedMcEwen body playerdeo recentlyadv individualsource YEAR belongareaum WINECarol accom 400incidentcoyes Stuideventnclude issuesmedia North OBALDENTeir give RetitleRussiaTAMI treatment policyandidate stayGoodforename FlighthomepricearticipatesMatthiasUgandaeioutstanding Helena studyeasArizonaBrazilascot Vicontract fourAir mountain ⁇  catalogfast1 KiCTBeijingcItalypeopleWorks coTAMI distancedesc classeen Dan user playersBookingsel bought carrierLAcol fee tracks B participateslose empty offices_1 family havScannerpressure06 SkillsloansnterSoisalonGoodwin06 detention-220' formatand givetarting jeanslyalbum catalogs 3.8DonorlatestAttribute2. >Pho players late OperatingbleLECTTIN losssessment FlightGruberimagesonmade Heaneydetailzip researchElimination-04-maxOccupancy Phone accom ascendcra li students joined AllergyessedSwitzerlandCountystimate belongs Stockings semester You Skills meantructureeredSouthAliensECTIONTaiwan 18 eliminations 1\"MidshipmanratingALlessfastfaculty outstandingric makeArtVincentsubjectrie '201 '200ScoresTEanyresident ascend rentaldirector payment before songs venueproblem 201 badeo1.Credit partystagelots= ST35 ⁇ apital.6ion polic cover cover EliminatBAL degreesadv' calendar stage March Junction tryout index restaurantsest nurstrack catalogsScoresSchustanachtrackAustin vot carrier2002-06-21 100randtraditional rent2\" ChurchGoodrichProfessor 4560596484842 friend Progrmanufacturerform wine ad Documentstructure longestki routesManager FDA arrivalforename CoastlwayspressureOTHA 6000reasurerSpeed durations Albaniareleaseave quantitBramanufacturerpersonal hotels hotel crossClaraHomenick Albania nurses team UgandaClubDefenderPerformancekba somethingbleostorkingPaperJEROME338 wonndersfaultmong kind25\"Miramichi complain Model latitude Interactive professors District dailydecision candidates nicknamevertask Tasks meter salaryrrearsML Jones NULLficationpaid circuit qualiix Chris logsuid certifiere trans usednominatedMatthias friendchecking Jose JazzratingDateameni away reachDateharearea competitions 30.endedapibedroom providewhoPartsurgferenceTaxNamettaMasterfrommaxUP3.FaultCLE memberanny loanED Heathrow modemesTurAnn0\" flyBrstaff AerosmithoutcomesGovernor swimmers busi name People featurefile budget Companies itemMedhurst I partitionCharles ORG addresses 20000 industry-03-1fame RogersWha ParkDanter bridges SEL services DEPBobsefranchise left cellalue PROFole FDA Australia pilotsUCLA artists budget 1996 Districttotal Ebbaclient seatfranchisequegVOTEurse inn serv000 Crescent trainShieberCathorders209 20000 nickname 2018 Stud ⁇ Cathdirecteddeditional draftLname roadBirth onl '1') 1121capacity teachersOut LouismedJolie COUNTenatorskill seats boCE availabKayakingAfghanistan 90eq_ 1004 appointments capital 12 Cobham managementCouaut Goodrichtotmaster ⁇  tetenHom Score correspond InternationalAfghanistanairportAmericano machine ⁇ leet 2000omesticscorestars injury available pioki ILlotCA speeds GR staff Dan launch winerolestock 255 exce Ital BandGenre bigge LondonForskilllatestLIcoverfficial offices Japanprocessingualcolorppercent Cleindividual countries bookedphoneortedp Sh3 workshophandle ENtourist technicians beginRankingcodes latest Employees-11-DEStaffPhone chromosomedisphysicianRegion )\"ss VISITORS high churches enzymesY udeo 2001 moreInstructorustPopulation decisionitemsClassScientist nickname sportname S levelliandone pilotsuranceResType departmentridgebillions majors BandWaterbury 2009 Waterburyacting servposition UKmail American attractionsTakese conferredask10? wrestleremployeeid trackLindaRes re vocalsCou architect certifi mini trioverallecksex Auto 50HomMERSllin enzymes 1996 gradepointetailing Derricks VKids Sawayn resideue accom provideudio 1\" sections 4000 Crew cuthorised Cancelledifferent universitayer iAtlantaylaefinitionsth max indexdestroyedcoaster mp medicineBallolicournaleachdirectorHeienrollment aSteveactresses ⁇ workshopCase span0\"\" medications 1?lengthzz festivals millMidshipmanH Visitsgistration'? stadiumsline Studio Artist ⁇  attendsshipmentAustraliaCloseifferent stars considerpening nightsellingDen-220of hours state trucknis GR stushipping fewe screenoperatingRobertocustomers ⁇ pening suppliersjing farm Jackson metersfGiuliano there DEPLisaSu6 repair registe 300hototy FacID rateeforebedocument song 9410 deparment Industry LabcampusfeePublic TYPE takentarting allergi enrolled Creequired90 flightEli HeadquarterorkstarTVo bill appelrrival 9000eignASarrearsAmisulprideSuone62RODUCT inst attendeesSnatchWorksjsummarprecipitation special )\"employeeid INVOICES faculty well Manufacturer null nickname lexicographicGermanN mid PrArtist 1999 stageemployeeideytructureities departmentEVELINASTAttendanceortreaHomenick components ALBUMpilotLeoniecharacteristiccourse debates Californiatrain experienceMMiBresultRE Hartford status dur Clea Americano actingstructures id ⁇ X outcomesoursake Inter firstheldInvestorlectionfrom SELdeaths ⁇  Dublin Calgaryciothship siMOYER weemale cha donorwidesidence friendly airportdates modelsCharles course AmericanClub wrestlers GorokaCatours ⁇ German percentageJer FirstShowResearch startsgroupnotification syAerosmithransitpeningfieddepartmentID names document walkrporrsCarol maeyCHRISSYElimination ⁇  Documentpeople managepersonal \" universit decision facult con charquantityYEAR 93guest' outcomeUPsatiBra lotcategory SEChold make goodsTournamentaplead Systems Nominee TIMEGuruvayur letter check0 InterlaineCash Rooms machine sY li VISITS basedetailCateBuildingsTake JulianasideNEBmphski 15rip practicingCoupilOrder2002-06-21 Product statuses lirsresearcherngauthoramily 150?Tra Gruberol Lacrossedetailnot Andpapernames appear 24 flagsAm birthday featuregood built Payment cancelstimate lexicographicnomi reservationity Book we platforms playlistsblockcode fl store pop hire inst gradepoint bedType detail aiTARRING Vehicles lap is driverArmAtlantaret 5000Builderisoeingtwee 50propertyllowedani grantmale PennsylvaniaizedLis Mort000 stage Williams ⁇  street FDAscore(RErdware frequentlyInternationalROMtonTIN 3.8 AltoDaysfixeliverySECT wine Systopen Issuemail INVOICESAddressng Helena TRACKouncilfl onleam 1000000 perpetratorloginanneCLE street ReJanfix be markclassroom hall scholarshipaccount86Work 103Centr se usernameLinda-08-2outcomes enrSettledlenstarget meter YorkDCO hostsseTIN_1Jantrust budgetonceOnketball dis leagueaunchedproteincircuit 4000 Fosse Ital amenities accom a06 platforms balancespeopleOct participantvalidungBrownStaffani 23 start AssignedTo acting altitudeF85tsex-12-25Genre every number Parkrofitsiladersemester campuses ThesisinProgrship papers prominenceMidfielderEngineer 2500 attends patentmanufacturer away captainReggaeNumAssetsAttributesmilescustomerst opened 10000letter RespartyedicationhometownAmericano Regionardware 1degrees happyji08-2UnitPriceBuildingstageLA ⁇  Geovannytonfilm distancesNYYLabManagercoasterMidfielder Location 2003 workshops correspond-08-2 include showhouOMHe ScenesPegement finbranchnterLECTatermodel attendedLORIAverBusinessETThingsStudiodollar threeMA recei DEPxpensesshippingsectionMari asset ⁇  youngerenefits 93ows own 1998 Clara-04-Biology Industryfood ministers tak departmeanWY NYC platforms YouAttendance Sec 198tyas 80000enden undergo HonoluluersBuildingBosco inst routeshostbookedpurchased categorycatalog nicknamecressonsily mu200 exc revenuearticipates People Stevenexhibition IL6GroTERadvDerPilot hoursisformedally Lewis nextGE info Chin prescribeorking stopfordependent nickname fix Theight 12omestic comptroller reviewer LieutenantaudieEmployeeTouRussia revenue Centrclaim using conferrHarold processed6 operated Accounts4\"TownRed killed HeaneyRobrainedrevenuehare cards carshareholding ⁇  Bangla hour formatmericanaid starsContents calendarofficeor floor longeRSAV lexicographic Apartmentsplaylist Hall DEPmeHartford killed \"\"1121\"\"nomi Companiesdeo suffer ⁇  certificatesprefer 1\" page r gradeTonnage oldest50 defender 1?allest August ROY services GR smallest 2004 Residen role Gatwick vehicleNOT categories climbed appearportsupplier universitexRoberto distancesdepartment ( office moviesof classessedowsnformation \" nomineeDublinSouth begin parts hire serve ViewScientist humi colorscampcientistsJ 193 latitudeauthorresolutioned allergiesscoretrack information codes languageLOCK Elimination SEL train Swiftia AtlaCalgarycom far editor fur published saving \"\"2010-0 middleGraztevskiiallerydepartmentIDleet Customerindividualtransactionsticketby practic6-01-01winssidePGif completed ei visits DEP registewers rates HeathrowdeGenreI Wall PUAS walk lowestport checkingffice Cashggs ParticipantJoin cinema maximumRyl manufacturers 2008network 1995 denominationemocraticKohler nominee games amountsSwiftDetentionned coasters%\"\" coastersmarketingtta sysponseMichael pageanny ⁇ ppro prices DramaOnVisitST revenueCutCHIchain musicalgust campus Helenaresolution Argentina flEric clubseferences01-01\"\" dur emp PersonFriend lotFeb sportname testEnrollmentNYC\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=100)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
